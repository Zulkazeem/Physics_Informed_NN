{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60682a0-6154-41bd-bfbc-435eaa2f2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e34b23c-22a6-44b0-a472-4e05c0119f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\yomid\\Downloads\\Elasticity_Final_Report\\PINNS\"\n",
    "output_file_path = r\"C:\\Users\\yomid\\Downloads\\Elasticity_Final_Report\\PINNS\\Data\\updated_json_file.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc1b23e6-b1e4-4c68-aa59-9e4a57875341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the function to process files and store columns as vectors with specific formatting\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Define the function to process files and store columns as vectors with specific formatting\n",
    "# def files_to_json(folder_path, output_file_path):\n",
    "#     all_vectors = []\n",
    "    \n",
    "#     # Iterate over all CSV files in the folder\n",
    "#     for file_name in os.listdir(folder_path):\n",
    "#         if file_name.endswith(\".csv\"):\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             try:\n",
    "#                 # Load the CSV file\n",
    "#                 df = pd.read_csv(file_path)\n",
    "                \n",
    "#                 # Initialize an empty list to store formatted columns\n",
    "#                 formatted_columns = []\n",
    "\n",
    "#                 # Iterate through all columns and format each one\n",
    "#                 for col in df.columns:\n",
    "#                     # Check if the column contains lists in string format (e.g., [50.0, -1.27, -1.27])\n",
    "#                     if isinstance(df[col].iloc[0], str) and df[col].iloc[0].startswith('[') and df[col].iloc[0].endswith(']'):\n",
    "#                         # Format this column as a list of floats with an additional 0.0\n",
    "#                         formatted_column = [list(map(float, value.strip('[]').split(','))) + [0.0] for value in df[col]]\n",
    "#                     else:\n",
    "#                         # If the column is numeric or doesn't contain lists, convert it to a list of floats\n",
    "#                         formatted_column = df[col].astype(float).tolist()\n",
    "                    \n",
    "#                     formatted_columns.append(formatted_column)\n",
    "                \n",
    "#                 # Append the formatted columns for this file\n",
    "#                 all_vectors.append(formatted_columns)\n",
    "#                 print(f\"Processed {file_path}\")\n",
    "            \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Failed to process {file_path}: {e}\")\n",
    "    \n",
    "#     # Save the vectors to a JSON file\n",
    "#     try:\n",
    "#         with open(output_file_path, 'w') as f:\n",
    "#             json.dump(all_vectors, f, indent=4)  # 'indent=4' for pretty-printing\n",
    "#         print(f\"Vectors saved to {output_file_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to save JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4950d2a6-b4e3-4937-8586-509d67eb7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# # Define the function to process files and store columns as vectors with specific formatting\n",
    "# def files_to_json(folder_path, output_file_path):\n",
    "#     graph_data = {\n",
    "#         \"nodes\": [],\n",
    "#         \"edges\": []\n",
    "#     }\n",
    "    \n",
    "#     # Iterate over all CSV files in the folder\n",
    "#     for file_name in os.listdir(folder_path):\n",
    "#         if file_name.endswith(\".csv\"):\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             try:\n",
    "#                 # Load the CSV file\n",
    "#                 df = pd.read_csv(file_path)\n",
    "                \n",
    "#                 # Iterate through rows and process each row as a node\n",
    "#                 for index, row in df.iterrows():\n",
    "#                     node = {\n",
    "#                         \"node_id\": index,  # Assign node ID\n",
    "#                         \"features\": {\n",
    "#                             \"Temp\": row[\"Temp\"],\n",
    "#                             \"Prev Temp\": row[\"Prev Temp\"],\n",
    "#                             \"Pipe Node\": list(map(float, row[\"Pipe Node\"].strip('[]').split(','))),\n",
    "#                             \"E_soil\": row[\"Soil Modulus (E_soil)\"],\n",
    "#                             \"Pressure_at_Node\": row[\"Pressure at Node\"],\n",
    "#                             \"Spring_Stiffness\": row[\"Spring Stiffness\"],\n",
    "#                             \"Pipe_Burst_Pressure\": row[\"Pipe Burst Pressure\"],\n",
    "#                             \"Burst_Occurred\": row[\"Burst Occurred\"],\n",
    "#                             \"Constant_Burst_Pressure\": row[\"Constant Burst Pressure\"],\n",
    "#                             \"Displacement\": row[\"Displacement\"]\n",
    "#                         }\n",
    "#                     }\n",
    "#                     graph_data[\"nodes\"].append(node)\n",
    "\n",
    "#                     # Generate edges between consecutive nodes (assuming this for simplicity)\n",
    "#                     if index > 0:  # Ensure no edge for the first node\n",
    "#                         edge = {\n",
    "#                             \"source\": index - 1,\n",
    "#                             \"target\": index,\n",
    "#                             \"features\": {\n",
    "#                                 \"distance\": 10.0,  # Example distance, customize as needed\n",
    "#                                 \"connection_type\": \"thermal\"  # Example connection type\n",
    "#                             }\n",
    "#                         }\n",
    "#                         graph_data[\"edges\"].append(edge)\n",
    "                \n",
    "#                 print(f\"Processed {file_path}\")\n",
    "            \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Failed to process {file_path}: {e}\")\n",
    "    \n",
    "#     # Save the graph data to a JSON file\n",
    "#     try:\n",
    "#         with open(output_file_path, 'w') as f:\n",
    "#             json.dump(graph_data, f, indent=4)  # 'indent=4' for pretty-printing\n",
    "#         print(f\"Graph data saved to {output_file_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to save JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2ac15a-7d81-4a06-a69b-f2b1ffb01325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to process files and store columns as vectors with specific formatting\n",
    "def files_to_json(folder_path, output_file_path):\n",
    "    graph_data = {\n",
    "        \"nodes\": [],\n",
    "        \"edges\": []\n",
    "    }\n",
    "    \n",
    "    # Iterate over all CSV files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # Load the CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Iterate through rows and process each row as a node\n",
    "                for index, row in df.iterrows():\n",
    "                    node = {\n",
    "                        \"node_id\": index,  # Assign node ID\n",
    "                        \"features\": {\n",
    "                            \"Temp\": row[\"Temp\"],\n",
    "                            \"Prev Temp\": row[\"Prev Temp\"],\n",
    "                            \"Pipe Node\": list(map(float, row[\"Pipe Node\"].strip('[]').split(','))) if isinstance(row[\"Pipe Node\"], str) else row[\"Pipe Node\"],\n",
    "                            \"E_soil\": row[\"Soil Modulus (E_soil)\"],\n",
    "                            \"Pressure_at_Node\": row[\"Pressure at Node\"],\n",
    "                            \"Spring_Stiffness\": row[\"Spring Stiffness\"],\n",
    "                            \"Pipe_Burst_Pressure\": row[\"Pipe Burst Pressure\"],\n",
    "                            \"Constant_Burst_Pressure\": row[\"Constant Burst Pressure\"],\n",
    "                            \"Displacement\": row[\"Displacement\"],\n",
    "                            \"Burst_Occurred\": row[\"Burst Occurred\"]\n",
    "                        }\n",
    "                    }\n",
    "                    graph_data[\"nodes\"].append(node)\n",
    "\n",
    "                    # Generate edges between consecutive nodes (assuming this for simplicity)\n",
    "                    if index > 0:  # Ensure no edge for the first node\n",
    "                        edge = {\n",
    "                            \"source\": index - 1,\n",
    "                            \"target\": index,\n",
    "                            \"features\": {\n",
    "                                \"distance\": 10.0,  # Example distance, customize as needed\n",
    "                                \"connection_type\": \"thermal\"  # Example connection type\n",
    "                            }\n",
    "                        }\n",
    "                        graph_data[\"edges\"].append(edge)\n",
    "                \n",
    "                print(f\"Processed {file_path}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {file_path}: {e}\")\n",
    "    \n",
    "    # Save the graph data to a JSON file\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            json.dump(graph_data, f, indent=4)  # 'indent=4' for pretty-printing\n",
    "        print(f\"Graph data saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save JSON file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85656b2a-c987-4c6f-9e2a-8d0fbcac9893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed C:\\Users\\yomid\\Downloads\\Elasticity_Final_Report\\PINNS\\Use_Data.csv\n",
      "Graph data saved to C:\\Users\\yomid\\Downloads\\Elasticity_Final_Report\\PINNS\\Data\\updated_json_file.json\n"
     ]
    }
   ],
   "source": [
    "files_to_json(folder_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556679cc-3517-47e8-a48b-40524a41ab78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
